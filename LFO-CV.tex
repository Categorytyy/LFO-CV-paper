\documentclass[american,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Approximate leave-future-out cross-validation for time series models},
            pdfauthor={Paul-Christian Bürkner, Jonah Gabry, Aki Vehtari},
            pdfkeywords={keywords},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[shorthands=off,main=american]{babel}
\else
  \usepackage{polyglossia}
  \setmainlanguage[variant=american]{english}
\fi
\usepackage{natbib}
\bibliographystyle{plainnat}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Approximate leave-future-out cross-validation for time series models}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Paul-Christian Bürkner, Jonah Gabry, Aki Vehtari}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
    \date{}
    \predate{}\postdate{}
  
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}

\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{setspace}
\onehalfspacing
\setcitestyle{round}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\begin{document}
\maketitle
\begin{abstract}
One of the most common goals of a time series analysis is to use the
observed series to inform predictions for future observations. In the
absence of any actual new data to predict, cross-validation can be used
to measure a model's predictive accuracy for instance for the purpose of
model comparison or selection. As exact cross-validation is often
practically infeasible for Bayesian models because it requires too much
time, approximate cross-validation methods have been developed; most
notably methods for leave-one-out cross-validation (LOO-CV). However,
for time-series models, it does not make sense to leave out observations
one at a time because then we are allowing information from the future
to influence predictions of the past. To apply the idea of
cross-validation to time-series models, we thus need some form of
leave-future-out cross-validation (LFO-CV). Like exact LOO-CV, exact
LFO-CV requires refitting the model many times to different subsets of
the data, which is computationally very costly for most nontrivial
examples, in particular for Bayesian models. Using Pareto-smoothed
importance sampling, we propose a method for approximating exact LFO-CV
that drastically reduces the computational burden while also providing
informative diagnostics about the quality of the approximation.
\end{abstract}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

TODO: general introduction to time-series

One of the most common goals of a time series analysis is to use the
observed series to inform predictions for future observations. We will
refer to this task of predicting a sequence of \(M\) future observations
as \(M\)-step-ahead prediction (\(M\)-SAP). Fortunately, once we have
fit a Bayesian model and can sample from the posterior predictive
distribution, it is straightforward to generate predictions as far into
the future as we want. It is also straightforward to evaluate the
\(M\)-SAP performance of a time series model by comparing the
predictions to the observed sequence of \(M\) future data points once
they become available.

Unfortunately, we are often in the position of having to use a model to
inform decisions \emph{before} we can collect the future observations
required for assessing the predictive performance. If we have many
competing models we may also need to first decide which of the models
(or which combination of the models) we should rely on for predictions.
In these situations the best we can do is to use methods for
approximating the expected predictive performance of our models using
only the observations of the time series we already have.

TODO: introduce cross-validation

If there were no time dependence in the data or if the focus is to
assess the non-time-dependent part of the model, we could use methods
like leave-one-out cross-validation (LOO-CV). For a data set with \(N\)
observations, we refit the model \(N\) times, each time leaving out one
of the \(N\) observations and assessing how well the model predicts the
left-out observation. LOO-CV is very expensive computationally in most
realistic settings, but the Pareto smoothed importance sampling
\citep[PSIS;][]{vehtari2017loo, vehtari2017psis} algorithm allows for
approximating exact LOO-CV with PSIS-LOO-CV. PSIS-LOO-CV requires only a
single fit of the full model and comes with diagnostics for assessing
the validity of the approximation.

With a time series we can do something similar to LOO-CV but, except in
a few cases, it does not make sense to leave out observations one at a
time because then we are allowing information from the future to
influence predictions of the past (i.e., times \(t + 1, t+2, \ldots\)
should not be used to predict for time \(t\)). To apply the idea of
cross-validation to the \(M\)-SAP case, instead of leave-\emph{one}-out
cross-validation we need some form of leave-\emph{future}-out
cross-validation (LFO-CV). As we will demonstrate in this case study,
LFO-CV does not refer to one particular prediction task but rather to
various possible cross-validation approaches that all involve some form
of prediction for new time series data. Like exact LOO-CV, exact LFO-CV
requires refitting the model many times to different subsets of the
data, which is computationally very costly for most nontrivial examples,
in particular for Bayesian analyses where refitting the model means
estimating a new posterior distribution rather than a point estimate.

Although PSIS-LOO-CV provides an efficient approximation to exact
LOO-CV, until now there has not been an analogous approximation to exact
LFO-CV that drastically reduces the computational burden while also
providing informative diagnostics about the quality of the
approximation. In this paper we present PSIS-LFO-CV, an algorithm that
typically only requires refitting the time-series model a small number
times and will make LFO-CV tractable for many more realistic
applications than previously possible.

TODO: structure of the paper

\hypertarget{m-step-ahead-predictions}{%
\section{\texorpdfstring{\(M\)-step-ahead
predictions}{M-step-ahead predictions}}\label{m-step-ahead-predictions}}

Assume we have a time series of observations
\(y = (y_1, y_2, \ldots, y_N)\) and let \(L\) be the \emph{minimum}
number of observations from the series that we will require before
making predictions for future data. Depending on the application and how
informative the data is, it may not be possible to make reasonable
predictions for \(y_{i}\) based on \((y_1, \dots, y_{i-1})\) until \(i\)
is large enough so that we can learn enough about the time series to
predict future observations. Setting \(L=10\), for example, means that
we will only assess predictive performance starting with observation
\(y_{11}\), so that we always have at least 10 previous observations to
condition on.

In order to assess \(M\)-SAP performance we would like to compute the
predictive densities

\begin{equation}
p(y_{i<M} \,|\, y_{<i}) = p(y_i, \ldots, y_{i + M - 1} \,|\, y_{1},...,y_{i-1}) 
\end{equation}

for each \(i \in \{L + 1, \ldots, N - M + 1\}\), where we use
\(y_{i<M} = (y_i, \ldots, y_{i + M - 1})\) and
\(y_{<i} = (y_{1}, \ldots, y_{i-1})\) to shorten the notation. The
quantities \(p(y_{i<M} \,|\, y_{<i})\) can be computed with the help of
the posterior distribution \(p(\theta \,|\, y_{<i})\) of the parameters
\(\theta\) conditional on only the first \(i-1\) observations of the
time-series:

\begin{equation}
p(y_{i<M} \,| \, y_{<i}) = 
  \int p(y_{i<M} \,| \, y_{<i}, \theta) \, p(\theta\,|\,y_{<i}) \,d\theta. 
\end{equation}

Having obtained \(S\) draws
\((\theta_{<i}^{(1)}, \ldots, \theta_{<i}^{(S)})\) from the posterior
distribution \(p(\theta\,|\,y_{<i})\), we can estimate
\(p(y_{i<M} | y_{<i})\) as

\begin{equation}
p(y_{i<M} \,|\, y_{<i}) \approx \frac{1}{S}
\sum_{s=1}^S p(y_{i<M} \,|\, y_{<i}, \theta_{<i}^{(s)}).
\end{equation}

In the following, we consider factorizable models in which the response
values are conditionally independent given the parameters and the
likelihood can be written in the familiar form

\begin{equation}
p(y \,|\, \theta) = \prod_{n=1}^N p(y_j \,|\, \theta).
\end{equation}

In this case, \(p(y_{i<M} \,|\, y_{<i}, \theta_{<i})\) reduces to
\begin{equation}
p(y_{i<M} \,|\, \theta_{<i}) = \prod_{n = i}^{i + M -1} p(y_j \,|\, \theta_{<i}),
\end{equation} due to the assumption of conditional independence between
\(y_{i<M}\) and \(y_{<i}\) given \(\theta_{<i}\). Non-factorizable
models, which do not make this assumption, are discussed in
\citet{buerkner:non-factorizable}.

\hypertarget{approximate_MSAP}{%
\subsection{\texorpdfstring{Approximate \(M\)-step-ahead
predictions}{Approximate M-step-ahead predictions}}\label{approximate_MSAP}}

Unfortunately, the math above makes use of the posterior distributions
from many different fits of the model to different subsets of the data.
That is, to obtain the predictive density \(p(y_{i<M} \,|\, y_{<i})\)
requires fitting a model to only the first \(i-1\) data points, and we
will need to do this for every value of \(i\) under consideration (all
\(i \in \{L + 1, \ldots, N - M + 1\}\)).

To reduce the number of models that need to be fit for the purpose of
obtaining each of the densities \(p(y_{i<M} \,|\, y_{<i})\), we propose
the following algorithm. Starting with \(i = N - M + 1\), we approximate
each \(p(y_{i<M} \,|\, y_{<i})\) using Pareto smoothed importance
sampling \citep[PSIS;][]{vehtari2017loo, vehtari2017psis}:

\begin{equation}
 p(y_{i<M} \,|\, y_{<i}) \approx
   \frac{ \sum_{s=1}^S w_i^{(s)}\, p(y_{i<M} \,|\, \theta^{(s)})}{ \sum_{s=1}^S w_i^{(s)}},
\end{equation}

where \(w_i^{(s)}\) are importance weights and \(\theta^{(s)}\) are
draws from the posterior distribution based on \emph{all} observations.
To obtain \(w_i^{(s)}\), we first compute the raw importance ratios

\begin{equation}
r_i^{(s)} \propto \frac{1}{\prod_{j \in J_i} p(y_j \,|\, \,\theta^{(s)})},
\end{equation}

and then stabilize them using PSIS as described in
\citet{vehtari2017psis}. The index set \(J_i\) contains all the indices
of observations which are part of the actually fitted model but not of
the model whose predictive performance we are trying to approximate.
That is, for the starting value \(i = N - M + 1\), we have
\(J_i = \{i, \ldots, N\}\). This approach to computing importance ratios
is a generalization of the approach used in PSIS-LOO-CV, where only a
single observation is left out at a time and thus \(J_i = i\) for all
\(i\).

Starting from \(i = N - M + 1\), we gradually \emph{decrease} \(i\) by
\(1\) (i.e., we move backwards in time) and repeat the process. At some
observation \(i\), the variability of importance ratios \(r_i^{(s)}\)
will become too large and importance sampling fails. We will refer to
this particular value of \(i\) as \(i^\star_1\). To identify the value
of \(i^\star_1\), we check for which value of \(i\) does the estimated
shape parameter \(k\) of the generalized Pareto distribution first cross
a certain threshold \(\tau\) \citep{vehtari2017psis}. Only then do we
refit the model using only observations before \(i^\star_1\) and then
restart the process. Until the next refit, we have
\(J_i = \{i, \ldots, i^\star_1 -1 \}\) for \(i < i^\star_1\), as the
refitted model only contains the observations up to index
\(N^\star_1 = i^\star_1 - 1\).

In some cases we may only need to refit once and in other cases we will
find a value \(i^\star_2\) that requires a second refitting, maybe an
\(i^\star_3\) that requires a third refitting, and so on. We repeat the
refitting as few times as is required (only if \(k > \tau\)) until we
arrive at \(i = L + 1\). Recall that \(L\) is the minimum number of
observations we have deemed acceptable for making predictions (setting
\(L=0\) means predictions of all observations should be computed).

TODO: visualisation

The threshold \(\tau\) is crucial to the accuracy and speed of the
proposed algorithm. If \(\tau\) is too large, we need fewer refits and
thus achieve higher speed, but accuracy is likely to suffer. If \(\tau\)
is too small, we get high accuracy but a lot of refits to that speed
will drop noticably. When performing exact CV of Bayesian models, almost
all of the computational time is spend fitting models, while the time
needed to do predictions is negligeble in comparison. That is, a
reduction of the number of refits basically implies a proportional
reduction in the overall time necessary for CV of Bayesian models.

A mathematical analysis of the Pareto distribution reveals that
approximate CV via PSIS is very likely to be highly accuracte as long as
\(k < 0.5\) \citep{vehtari2017psis}. In practice, PSIS-LOO-CV turned out
to be robust for \(k < 0.7\) \citep{vehtari2017loo}. That is, for
PSIS-LFO-CV introduced in the present paper, we can expect an
appropriate threshold to be somewhere between
\(0.5 \leq \tau \leq 0.7\). It is unlikely to be as high as
\(\tau = 0.7\), as the error made in the prediction of a certain
observation \(i\) will propagate to the predictions of observations
\(i-1, i-2, \ldots\) until a refit is performed. That is, problematic
observations with high \(k\) are likely to have stronger effects in
LFO-CV than LOO-CV. We will come back to the issue of setting approriate
thresholds in Section \ref{simulations}.

\hypertarget{block-m-step-ahead-predictions}{%
\subsection{\texorpdfstring{Block \(M\)-step-ahead
predictions}{Block M-step-ahead predictions}}\label{block-m-step-ahead-predictions}}

Depending on the particular time-series data and model, the Pareto \(k\)
estimates may exceed \(\tau\) rather quickly (i.e., after only few
observations) and so a lot of refits may be required even when carrying
out the PSIS approximation to LFO-CV. In this case, another option is to
exclude only the block of \(B\) future values that directly follow the
observations to be predicted while retaining all of the more distant
values \(y_{i>B} = (y_{i + B}, \ldots, y_N)\). This will usually result
in lower Pareto \(k\) estimates and thus less refitting, but crucially
alters the underlying prediction task, to which we will refer to as
block-\(M\)-SAP.

The block-\(M\)-SAP version closely resembles the basic \(M\)-SAP only
if values in the distant future, \(y_{>B}\), contain little information
about the current observations being predicted, apart from just
increasing precision of the estimated parameters. Whether this
assumption is justified will depend on the data and model. That is, if
the time-series is non-stationary, distant future value will inform
overall trends in the data and thus clearly inform predictions of the
current observations being left-out. As a result, block-LFO-CV is only
recommended for stationary time-series and corrsponding models.

There are more complexities that arise in block-\(M\)-SAP that we did
not have to care about in standard \(M\)-SAP. One is that, by just
removing the block, the time-series effectively gets split into two
parts, one before and one after the block. This poses no problem for
conditionally independent time-series models, where predictions just
depend on the parameters and not on the former values of the time-series
itself. However, if the model's predictions are \emph{not} conditionally
independent as is the case, for instance, in autoregressive models (see
Section X), the observations of the left-out block have to be modeled as
missing values in order to retain the integreity of the time-series'
predictions after the block. A related example from spatial statistics,
in which the modeling of missing values is required for valid inference,
can be found in \citet{buerkner:non-factorizable}.

Another complexity concerns the PSIS approximation of block-LFO-CV: Not
only does the approximating model contain more observations than the
current model whose predictions we are approximating, but it also may
\emph{not} contain observations that are present in the actual model.
The latter observations are those right after the currently left-out
block, which are included in the current model, but not in the
approximating model as they were part of the block at the time the
approximating model was (re-)fit. A visualitation of this situation is
provided in Figure X. More formally, let \(\overline{J}_i\) be the index
set of observations that are missing in the approximating model at the
time of predicting observation \(i\). We find

\begin{equation}
\overline{J}_i = \{ \max(i + B, N^\star + 1), \ldots, \min(N^\star + B, N) \}
\end{equation}

if \(\max(i + B, N^\star + 1) \leq \min(N^\star + B, N)\) and
\(\overline{J}_i = \emptyset\) otherwise. As above, \(N^\star\) refers
to the largest observation included in the model fitting, that is
\(N^\star = i^\star - 1\) where \(i^*\) is the index of the latest
refit. The raw importance ratios \(r_i^{(s)}\) for each posterior draw
\(s\) are then computed as

\begin{equation}
r_i^{(s)} \propto \frac{\prod_{j \in \overline{J}_i} p(y_j \,|\, \,\theta^{(s)})}
{\prod_{j \in J_i} p(y_j \,|\, \,\theta^{(s)})}
\end{equation}

before they are stabilized and further processed using PSIS (see Section
\ref{approximate_MSAP}).

\hypertarget{simulations}{%
\section{Simulations}\label{simulations}}

To evaluate the goodness of the approximation of PSIS-LFO-CV, we
performed a simulation study by systematically varying the following
conditions: The number \(M\) of future observations to be predicted took
on values of \(M = 1\) and \(M = 4\). The number of future values to be
excluded in the model fitting took on values of \(B = \infty\) (i.e.,
leaving out the whole future), or \(B = 10\) (i.e.~leaving out only a
block of 10 observations). The threshold \(\tau\) of the Pareto \(k\)
estimates was varied between \(k = 0.5\) to \(k = 0.7\) in steps of
\(0.1\). In addition, we evaluated six different data generating models
with linear and/or quadatric terms and/or autoregressive terms of order
2 (see Table X for an overview). These models are also illustrated
graphically in Figure \ref{simmodels}.

\begin{figure}
\centering
\includegraphics{LFO-CV_files/figure-latex/simmodels-1.pdf}
\caption{Illustration of the models used in the simulations.}
\end{figure}

Autoregressive (AR) models are some of the most commonly used
time-series models. An AR(p) model -- an autoregressive model of order
\(p\) -- can be defined as

\begin{equation}
y_i = \eta_i + \sum_{k = 1}^p \varphi_k y_{i - k} + \varepsilon_i,
\end{equation}

where \(\eta_i\) is the linear predictor for the \(i\)th observation,
\(\phi_k\) are the autoregressive parameters and \(\varepsilon_i\) are
pairwise independent errors, which are usually assumed to be normally
distributed with equal variance \(\sigma^2\). The model implies a
recursive formula that allows for computing the right-hand side of the
above equation for observation \(i\) based on the values of the
equations for previous observations. Thus, by definition, responses of
AR-models are not conditionally independent. However they are still
factorizable, that is we may write down a separate likelihood
contribution per observation \citep[see][ for more discussion on
factorizability of statistical models]{buerkner:non-factorizable}.

\hypertarget{results}{%
\subsection{Results}\label{results}}

\begin{figure}
\centering
\includegraphics{LFO-CV_files/figure-latex/1sap-1.pdf}
\caption{Simulation results of 1-step-ahead predictions.}
\end{figure}

\begin{figure}
\centering
\includegraphics{LFO-CV_files/figure-latex/block1sap-1.pdf}
\caption{Simulation results of block 1-step-ahead predictions.}
\end{figure}

\begin{figure}
\centering
\includegraphics{LFO-CV_files/figure-latex/4sap-1.pdf}
\caption{Simulation results of 4-step-ahead predictions.}
\end{figure}

\begin{figure}
\centering
\includegraphics{LFO-CV_files/figure-latex/block4sap-1.pdf}
\caption{Simulation results of block 4-step-ahead predictions.}
\end{figure}

\hypertarget{case-studies}{%
\section{Case Studies}\label{case-studies}}

\hypertarget{annual-measurements-of-the-level-of-lake-huron}{%
\subsection{Annual measurements of the level of Lake
Huron}\label{annual-measurements-of-the-level-of-lake-huron}}

To illustrate the application of PSIS-LFO-CV for estimating expected
\(M\)-SAP performance, we will fit a model for 98 annual measurements of
the water level (in feet) of
\href{https://en.wikipedia.org/wiki/Lake_Huron}{Lake Huron} from the
years 1875--1972. This data set is found in the \emph{datasets} R
package, which is installed automatically with R \citep{R2018}. The
time-series shows rather strong autocorrelation of the well as some
trend towards lower levels for later points in time. We fit an AR(4)
model and display the model implied predictions along with the observed
values in Figure \ref{fig:lake-huron}.

\begin{figure}
\centering
\includegraphics{LFO-CV_files/figure-latex/lake-huron-1.pdf}
\caption{Water Level in Lake Huron (1875-1972). Black points are
observed data. The blue line represents mean predictions of an AR(4)
model with 90\% prediction intervals shown in gray.}
\end{figure}

Based on this data and model, we will illustrate the use of PSIS-LFO-CV
to provide estimates of \(1\)-SAP and \(4\)-SAP leaving out all future
values as well as leaving out only a block of future values. To allow
for reasonable predictions of future values, we will require at least
\(L = 20\) historical observations (20 years) to make predictions.
Further, we set a threshold of \(\tau =\) 0.6 for the Pareto \(k\) value
at which define that refitting becomes necessary.

We start by computing exact and PSIS-approximated LFO-CV of 1-SAP where
we leave out all future values. We compute \({\rm elpd}_{\rm exact} =\)
-93.38 and \({\rm elpd}_{\rm approx} =\) -91.73, which are highly
similar. Plotting the Pareto \(k\) estimates reveals that the model had
to be refit 4 times, out of a total of \(N - L =\) 78 predicted
observations (see Figure \ref{fig:pareto-k-lh}). On average, this means
one refit every 19.5 observations, which implies a drastic speed
increase as compared to exact LFO-CV. Performing LFO-CV of 4-SAP leaving
out all future values, we compute \({\rm elpd}_{\rm exact} =\) -538.68
and \({\rm elpd}_{\rm approx} =\) -539.58, which are again similar. In
general, for increasing \(M\), the approximation tends to become less
accurate in absolute elpd units, as the elpd increment of each
observation will be based on more and more observations. Since, for
constant threshold \(\tau\), the importance weights are the same
independent of \(M\), Pareto \(k\) estimates are also the same in
\(4\)-SAP as in \(1\)-SAP.

\begin{figure}
\centering
\includegraphics{LFO-CV_files/figure-latex/pareto-k-lh-1.pdf}
\caption{Pareto \(k\) estimates for PSIS-LFO-CV of 1 and 4 step-ahead
predictions leaving out all future values. The dotted red line indicates
the threshold at which the refitting was necessary.}
\end{figure}

It is not entirely clear how stationary the time-series is as it may
have a slight negative trend across time. However, the AR(4) model we
are using assumes stationarity and it is appropriate to also use
block-LFO-CV for this example, at least for illustrationary purposes. We
choose to leave out a block of \(B = 10\) future values as the
dependency of an AR(4) model will not reach that far into the future.
That is, we will include all observations after this block when
re-fitting the model.

Approximate LFO-CV of block-1-SAP reveals \({\rm elpd}_{\rm exact} =\)
-88.55 and \({\rm elpd}_{\rm approx} =\) -87.99, which are highly
similar. Plotting the Pareto \(k\) estimates reveals that the model had
to be refit 2 times, out of a total of \(N - L =\) 78 predicted
observations (see Figure \ref{fig:pareto-k-lh-block}). On average, this
means one refit every 39 observations, which again implies a drastic
speed increase as compared to exact LFO-CV. What is more, we needed even
fewer refits than in non-block LFO-CV, an observation we already made in
our simulation in Section \ref{simulations}. Performing LFO-CV of
block-4-SAP, we compute \({\rm elpd}_{\rm exact} =\) -484.25 and
\({\rm elpd}_{\rm approx} =\) -488.81, which are again similar but not
quite a close as in the 1-SAP case. Since AR-models fall in the class of
conditionally dependent models, predicting observations right after the
left-out block may be quite difficult as shown in Section
\ref{simulations}. However, for the present data set, the PSIS
apprixmations of block-LFO-CV seem to have worked out just fine.

\begin{figure}
\centering
\includegraphics{LFO-CV_files/figure-latex/pareto-k-lh-block-1.pdf}
\caption{Pareto \(k\) estimates for PSIS-LFO-CV of 1 and 4 step-ahead
predictions leaving out a block of 10 future values. The dotted red line
indicates the threshold at which the refitting was necessary.}
\end{figure}

\hypertarget{annual-date-of-the-cherry-blossom-in-japan}{%
\subsection{Annual date of the cherry blossom in
Japan}\label{annual-date-of-the-cherry-blossom-in-japan}}

\begin{figure}
\centering
\includegraphics{LFO-CV_files/figure-latex/cherry-blossom-1.pdf}
\caption{Day of the cherry blossom in Japan (812-2015). Black points are
observed data. The blue line represents mean predictions of a thin-plate
spline model with 90\% regression intervals shown in gray.}
\end{figure}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

TODO: discuss the possibility to compute bayes factors.

\newpage

\hypertarget{refs}{}

\bibliography{LFO-CV.bib}


\end{document}
